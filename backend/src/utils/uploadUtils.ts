import type { MulterFile } from '../types/express.d.ts'
import { getUploadConfig } from '../config/env.js'
import { v4 as uuidv4 } from 'uuid'

// üéØ Upload Queue Management
interface UploadJob {
  id: string
  userId: string
  file: MulterFile
  priority: 'high' | 'normal' | 'low'
  status: 'pending' | 'processing' | 'completed' | 'failed'
  progress: number
  createdAt: Date
  startedAt?: Date
  completedAt?: Date
  error?: string
}

class UploadQueue {
  private queue: UploadJob[] = []
  private processing = false

  async addJob(userId: string, file: MulterFile, priority: 'high' | 'normal' | 'low' = 'normal'): Promise<string> {
    const job: UploadJob = {
      id: uuidv4(),
      userId,
      file,
      priority,
      status: 'pending',
      progress: 0,
      createdAt: new Date()
    }
    
    this.queue.push(job)
    this.queue.sort((a, b) => {
      const priorityOrder = { high: 3, normal: 2, low: 1 }
      return priorityOrder[b.priority] - priorityOrder[a.priority]
    })
    
    if (!this.processing) {
      this.processQueue()
    }
    
    return job.id
  }

  private async processQueue() {
    this.processing = true
    
    while (this.queue.length > 0) {
      const job = this.queue.shift()!
      job.status = 'processing'
      job.startedAt = new Date()
      
      try {
        // Process the upload
        await this.processUpload(job)
        job.status = 'completed'
        job.progress = 100
        job.completedAt = new Date()
      } catch (error) {
        job.status = 'failed'
        job.error = error instanceof Error ? error.message : 'Unknown error'
      }
    }
    
    this.processing = false
  }

  private async processUpload(job: UploadJob) {
    // Simulate progress updates
    for (let i = 0; i <= 100; i += 10) {
      job.progress = i
      await new Promise(resolve => setTimeout(resolve, 100))
    }
    
    // TODO: Implement actual upload logic
    console.log(`Processing upload job ${job.id} for user ${job.userId}`)
  }

  getJobStatus(jobId: string): UploadJob | null {
    return this.queue.find(job => job.id === jobId) || null
  }

  getUserJobs(userId: string): UploadJob[] {
    return this.queue.filter(job => job.userId === userId)
  }
}

// üéØ Chunked Upload Support
interface ChunkInfo {
  chunkNumber: number
  totalChunks: number
  chunkSize: number
  totalSize: number
  fileId: string
  fileName: string
}

class ChunkedUploadManager {
  private chunks: Map<string, Buffer[]> = new Map()
  private uploadConfig = getUploadConfig()

  async processChunk(chunkInfo: ChunkInfo, chunkData: Buffer): Promise<{ success: boolean; message: string }> {
    const { fileId, chunkNumber, totalChunks } = chunkInfo
    
    if (!this.chunks.has(fileId)) {
      this.chunks.set(fileId, [])
    }
    
    const fileChunks = this.chunks.get(fileId)!
    fileChunks[chunkNumber] = chunkData
    
    // Check if all chunks received
    if (fileChunks.filter(chunk => chunk !== undefined).length === totalChunks) {
      return await this.assembleFile(fileId, chunkInfo)
    }
    
    return { success: true, message: `Chunk ${chunkNumber + 1}/${totalChunks} received` }
  }

  private async assembleFile(fileId: string, chunkInfo: ChunkInfo): Promise<{ success: boolean; message: string }> {
    const fileChunks = this.chunks.get(fileId)!
    const assembledBuffer = Buffer.concat(fileChunks)
    
    // TODO: Process the assembled file
    console.log(`File ${fileId} assembled successfully (${assembledBuffer.length} bytes)`)
    
    // Clean up chunks
    this.chunks.delete(fileId)
    
    return { success: true, message: 'File assembled successfully' }
  }
}

// üéØ Resumable Upload Support
interface UploadSession {
  sessionId: string
  userId: string
  fileName: string
  totalSize: number
  uploadedSize: number
  chunks: Set<number>
  createdAt: Date
  lastActivity: Date
}

class ResumableUploadManager {
  private sessions: Map<string, UploadSession> = new Map()
  private readonly sessionTimeout = 24 * 60 * 60 * 1000 // 24 hours

  createSession(userId: string, fileName: string, totalSize: number): string {
    const sessionId = uuidv4()
    const session: UploadSession = {
      sessionId,
      userId,
      fileName,
      totalSize,
      uploadedSize: 0,
      chunks: new Set(),
      createdAt: new Date(),
      lastActivity: new Date()
    }
    
    this.sessions.set(sessionId, session)
    return sessionId
  }

  updateSession(sessionId: string, chunkNumber: number, chunkSize: number): boolean {
    const session = this.sessions.get(sessionId)
    if (!session) return false
    
    session.chunks.add(chunkNumber)
    session.uploadedSize += chunkSize
    session.lastActivity = new Date()
    
    return true
  }

  getSession(sessionId: string): UploadSession | null {
    const session = this.sessions.get(sessionId)
    if (!session) return null
    
    // Check if session expired
    if (Date.now() - session.lastActivity.getTime() > this.sessionTimeout) {
      this.sessions.delete(sessionId)
      return null
    }
    
    return session
  }

  cleanupExpiredSessions(): void {
    const now = Date.now()
    for (const [sessionId, session] of this.sessions.entries()) {
      if (now - session.lastActivity.getTime() > this.sessionTimeout) {
        this.sessions.delete(sessionId)
      }
    }
  }
}

// üéØ Video Processing Utilities
interface VideoMetadata {
  duration: number
  width: number
  height: number
  bitrate: number
  codec: string
  fps: number
}

class VideoProcessor {
  async extractMetadata(filePath: string): Promise<VideoMetadata> {
    try {
      const { exec } = await import('child_process')
      const { promisify } = await import('util')
      const execAsync = promisify(exec)

      // Use ffprobe to get video metadata
      const ffprobeCommand = `ffprobe -v quiet -print_format json -show_format -show_streams "${filePath}"`
      const { stdout } = await execAsync(ffprobeCommand)
      const metadata = JSON.parse(stdout)

      // Extract video stream info
      const videoStream = metadata.streams?.find((stream: any) => stream.codec_type === 'video')
      const format = metadata.format

      if (!videoStream || !format) {
        throw new Error('Could not extract video metadata')
      }

      const duration = parseFloat(format.duration || '0')
      const width = parseInt(videoStream.width || '1920')
      const height = parseInt(videoStream.height || '1080')
      const bitrate = parseInt(format.bit_rate || '5000000')
      const codec = videoStream.codec_name || 'h264'
      const fps = eval(videoStream.r_frame_rate || '30/1') // Handle fractional frame rates

      console.log(`üìä [VideoProcessor] Extracted metadata: ${duration}s, ${width}x${height}, ${codec}, ${fps}fps`)

      return {
        duration,
        width,
        height,
        bitrate,
        codec,
        fps
      }
    } catch (error) {
      console.error('‚ùå [VideoProcessor] Failed to extract metadata:', error)
      // Fallback to basic metadata
      return {
        duration: 60, // Default fallback
        width: 1920,
        height: 1080,
        bitrate: 5000000,
        codec: 'h264',
        fps: 30
      }
    }
  }

  async generateThumbnail(file: MulterFile, timestamp: number = 1): Promise<Buffer> {
    // TODO: Implement thumbnail generation using ffmpeg
    // This is a placeholder implementation
    return Buffer.from('thumbnail-placeholder')
  }

  async compressVideo(file: MulterFile, quality: 'low' | 'medium' | 'high' = 'medium'): Promise<Buffer> {
    // TODO: Implement video compression using ffmpeg
    // This is a placeholder implementation
    return file.buffer
  }
}

// üéØ Batch Upload Support
interface BatchUploadResult {
  batchId: string
  totalFiles: number
  successful: number
  failed: number
  results: Array<{
    fileName: string
    success: boolean
    moduleId?: string
    error?: string
  }>
}

class BatchUploadManager {
  async processBatch(files: MulterFile[], userId: string): Promise<BatchUploadResult> {
    const batchId = uuidv4()
    const results: BatchUploadResult['results'] = []
    let successful = 0
    let failed = 0

    for (const file of files) {
      try {
        // TODO: Implement actual upload logic
        const moduleId = uuidv4()
        results.push({
          fileName: file.originalname,
          success: true,
          moduleId
        })
        successful++
      } catch (error) {
        results.push({
          fileName: file.originalname,
          success: false,
          error: error instanceof Error ? error.message : 'Unknown error'
        })
        failed++
      }
    }

    return {
      batchId,
      totalFiles: files.length,
      successful,
      failed,
      results
    }
  }
}

// üéØ Export instances
export const uploadQueue = new UploadQueue()
export const chunkedUploadManager = new ChunkedUploadManager()
export const resumableUploadManager = new ResumableUploadManager()
export const videoProcessor = new VideoProcessor()
export const batchUploadManager = new BatchUploadManager()

// üéØ Utility functions
export const calculateChunkSize = (fileSize: number, maxChunkSize: number = 1024 * 1024): number => {
  return Math.min(maxChunkSize, fileSize)
}

export const validateChunkInfo = (chunkInfo: ChunkInfo): boolean => {
  return (
    chunkInfo.chunkNumber >= 0 &&
    chunkInfo.totalChunks > 0 &&
    chunkInfo.chunkNumber < chunkInfo.totalChunks &&
    chunkInfo.totalSize > 0 &&
    chunkInfo.fileId.length > 0 &&
    chunkInfo.fileName.length > 0
  )
}

export const formatUploadProgress = (uploaded: number, total: number): string => {
  const percentage = Math.round((uploaded / total) * 100)
  return `${percentage}% (${formatBytes(uploaded)} / ${formatBytes(total)})`
}

const formatBytes = (bytes: number): string => {
  if (bytes === 0) return '0 B'
  const k = 1024
  const sizes = ['B', 'KB', 'MB', 'GB']
  const i = Math.floor(Math.log(bytes) / Math.log(k))
  return parseFloat((bytes / Math.pow(k, i)).toFixed(1)) + ' ' + sizes[i]
} 