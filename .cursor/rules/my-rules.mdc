# Adapt V3 â€“ Cursor Rules (OpenAI-first, Voice-on-Web by default)

0) CONTEXT PRELOAD
You are editing Adapt V3, a mobile-first web app (iOS Safari + Android Chrome).
Do only what the Change Plan lists.  
No drive-by refactors, renames, or dependency churn.  
Do not change providers (Clerk, S3, Prisma/Postgres, QStash) unless the plan says so.  

AI policy: **OpenAI primary**, Gemini disabled (kept as placeholder).  
Uploads: **direct-to-S3 only, no chunking**.  
Normalization: all uploaded videos must be browser-safe MP4 (H.264 + AAC) via ffmpeg.  

---

1) What this app is
Turns owner training videos into interactive, timestamped steps + clickable transcript.  
Trainees: watch, tap transcript to seek, ask context-aware AI Tutor.  
Owners: edit steps inline, save, see repeated questions to improve training.  
Goals: (1) reliable videoâ†’transcriptâ†’steps pipeline, (2) mobile UX, (3) contextual AI, (4) multi-tenant ready.

2) Tech stack
Frontend: React 18 + TS + Vite, Tailwind, Zustand, Clerk, React Router, Vercel  
Backend: Express + TS, Prisma + PostgreSQL (Render), AWS S3, QStash (optional â†’ inline fallback), Render  
AI: OpenAI (gpt-4o-mini). Gemini present but disabled.  
Transcription: OpenAI Whisper (primary). Google Speech adapters exist but disabled.  
Voice (UI): Browser Web Speech API (free). Google STT/TTS kept behind flags.  

3) Mobile-first rules
375px width baseline; 44px+ touch targets; keyboard focus states.  
Video player full-width; steps clickable; sticky mic/controls where needed.  
Optimize for 4G (short timeouts, retries, progressive loading).  

4) Repo conventions
frontend/ (React) â€” backend/ (Express).  
Aliases: @components, @hooks, @stores, @utils, @config, @services, @routes, @types.  
Lint: ESLint + Prettier. Avoid `any`.

5) Data & storage
Uploads: direct-to-S3 via presigned URL.  
Backend: normalizes every upload â†’ H.264 + AAC MP4 â†’ stores with `ContentType=video/mp4`.  
DB: stores metadata + S3 key, not public URLs. Playback uses signed URLs.  
Heavy work (transcribeâ†’stepsâ†’embeddings): QStash jobs; inline fallback allowed with locking.  

6) API contracts (stable unless FE/BE PR shipped together)
- `POST /api/upload/init` â†’ presign { moduleId, key }  
- Client uploads â†’ `POST /api/upload/complete` â†’ enqueue/inline process  
- `GET /api/modules/:id` â†’ module + steps + transcript + statuses  
- `GET /api/video/:moduleId/play` â†’ short-lived signed URL  
- `POST /api/steps/:moduleId` â†’ upsert steps  
- `POST /api/qa/ask` â†’ { moduleId, stepId?, question } â†’ { answer, sources? }  
- `GET /api/qa/related?moduleId=...&q=...`  

7) AI prompting & cost guardrails
Provider: OpenAI only.  
Model: gpt-4o-mini. Temp=0.2, Max=800 tokens.  
Transcript trim to ~8â€“10k chars (head+tail+sampled middle).  
Retries â‰¤2 with backoff. No retries while status=PROCESSING.  
Prompt includes: moduleId, stepId?, last N turns, â‰¤3 transcript snippets.  

8) Voice (live STT/TTS for training)
Default: Web Speech API for STT+TTS.  
Google adapters kept but disabled. Guard with flags/env keys.  
Start Training â†’ mic overlay opens.  
TTS replies via Web Speech. Visible stop button; respect mute state.  

9) Performance
Controllers >1s must enqueue; inline only with spinner+lock.  
Video via signed URLs + range requests.  
Optional 30â€“60s caching for read-heavy endpoints.  

10) Testing
- Layout/tap tests iOS Safari + Android Chrome.  
- Contract tests for section 6 endpoints.  
- One happy-path e2e: upload â†’ process â†’ steps â†’ edit â†’ ask (incl. voice start).  

11) Strict Edit Scope
Every change begins with a Change Plan comment.  
Touch only listed files.  
If new file required, amend plan.  
No renames or dependency bumps without approval.  

12) Env & secrets
Base: DATABASE_URL, S3_*, CLERK_*, FRONTEND_ORIGIN, BACKEND_ORIGIN, OPENAI_API_KEY  
Flags:  
```env
ENABLE_GEMINI=false
AI_PROVIDER=openai
AI_MODEL_OPENAI=gpt-4o-mini
AI_TEMPERATURE=0.2
AI_MAX_OUTPUT_TOKENS=800

VOICE_STT_PROVIDER=web
VOICE_TTS_PROVIDER=web
ENABLE_GOOGLE_SPEECH=false
GOOGLE_PROJECT_ID=
GOOGLE_APPLICATION_CREDENTIALS=

QSTASH_ENABLED=false


his version merges your earlier â€œoverall pictureâ€ with the newer decisions:  
- ğŸ”’ **Direct-to-S3 only** (no chunking)  
- ğŸ¬ **FFmpeg normalization** required for every video before S3 upload  
- ğŸ§  **OpenAI only** (Gemini disabled but placeholder kept)  
- ğŸ¤ **Voice via Web Speech API** by default  
- âœ… Clarified env vars and error guardrails  



Update 8.19.25
The Recommendations I Gave You (Best Practices)

Direct-to-S3 Uploads â†’ Browser uploads go straight to S3 instead of proxying through your server.
âœ… Reduces errors, avoids Render bandwidth issues, lowers cost, and is industry standard.

Force MP4 Normalization via FFmpeg â†’ Re-encode all uploads to H.264/AAC MP4 so they always play in browsers.
ğŸ’² ~$0.03 per processed minute on AWS Elastic Transcoder or MediaConvert.
âœ… Guarantees no playback issues, even with weird iPhone MOV/WebM uploads.

Async Job Queue (QStash/Redis) â†’ Offload heavy AI/video processing so uploads donâ€™t block users.
ğŸ’² QStash = $1 free tier (10k req) â†’ ~$10/month for your current testing load.
âœ… Keeps UX smooth during AI transcription/step generation.

CDN (CloudFront) â†’ Cache videos close to users, remove latency.
ğŸ’² First 1TB = $85 on AWS; unnecessary for now.
âœ… Matters only at larger scale.

Database as Source of Truth â†’ Always track upload status, key, URL in Postgres.
âœ… Ensures no dangling files, simplifies frontend logic.

What We Are Doing Now

âœ… Direct-to-S3 Uploads â†’ Implementing presigned PUT URLs.

âœ… Database as Source of Truth â†’ Adding a Video table to track uploads + status.

âŒ Skipping FFmpeg normalization (for now) â†’ Saves cost + complexity during testing.

âŒ Skipping async job queue (for now) â†’ Less moving parts, no extra infra.

âŒ Skipping CDN (for now) â†’ Not needed at low traffic.

âŒ Skipping structured logging/multi-stage builds (for now) â†’ Keep dev simple until stability.